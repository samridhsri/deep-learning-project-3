{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "import numpy as np\n",
    "from tqdm import tqdm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_DIR = \"../TestDataSet\"\n",
    "LABELS_JSON_PATH = os.path.join(DATASET_DIR, \"labels_list.json\")\n",
    "PRETRAINED_WEIGHTS = torchvision.models.ResNet34_Weights.IMAGENET1K_V1\n",
    "BATCH_SIZE = 32\n",
    "NUM_WORKERS = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ResNet-34 model with ResNet34_Weights.IMAGENET1K_V1 weights...\n",
      "Downloading: \"https://download.pytorch.org/models/resnet34-b627a593.pth\" to /Users/shikharmalik/.cache/torch/hub/checkpoints/resnet34-b627a593.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 83.3M/83.3M [00:18<00:00, 4.79MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded and set to evaluation mode.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Loading ResNet-34 model with {PRETRAINED_WEIGHTS} weights...\")\n",
    "model = torchvision.models.resnet34(weights=PRETRAINED_WEIGHTS)\n",
    "model = model.to(DEVICE)\n",
    "model.eval()\n",
    "print(\"Model loaded and set to evaluation mode.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "MEAN_NORMS = np.array([0.485, 0.456, 0.406])\n",
    "STD_NORMS = np.array([0.229, 0.224, 0.225])\n",
    "\n",
    "eval_transforms = T.Compose([\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=MEAN_NORMS, std=STD_NORMS)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loading dataset from: ../TestDataSet\n",
      "[INFO] Dataset loaded: 500 images across 100 classes.\n",
      "[INFO] Class index order (alphabetical): ['n02672831', 'n02676566', 'n02687172', 'n02690373', 'n02692877', 'n02699494', 'n02701002', 'n02704792', 'n02708093', 'n02727426', 'n02730930', 'n02747177', 'n02749479', 'n02769748', 'n02776631', 'n02777292', 'n02782093', 'n02783161', 'n02786058', 'n02787622', 'n02788148', 'n02790996', 'n02791124', 'n02791270', 'n02793495', 'n02794156', 'n02795169', 'n02797295', 'n02799071', 'n02802426', 'n02804414', 'n02804610', 'n02807133', 'n02808304', 'n02808440', 'n02814533', 'n02814860', 'n02815834', 'n02817516', 'n02823428', 'n02823750', 'n02825657', 'n02834397', 'n02835271', 'n02837789', 'n02840245', 'n02841315', 'n02843684', 'n02859443', 'n02860847', 'n02865351', 'n02869837', 'n02870880', 'n02871525', 'n02877765', 'n02879718', 'n02883205', 'n02892201', 'n02892767', 'n02894605', 'n02895154', 'n02906734', 'n02909870', 'n02910353', 'n02916936', 'n02917067', 'n02927161', 'n02930766', 'n02939185', 'n02948072', 'n02950826', 'n02951358', 'n02951585', 'n02963159', 'n02965783', 'n02966193', 'n02966687', 'n02971356', 'n02974003', 'n02977058', 'n02978881', 'n02979186', 'n02980441', 'n02981792', 'n02988304', 'n02992211', 'n02992529', 'n02999410', 'n03000134', 'n03000247', 'n03000684', 'n03014705', 'n03016953', 'n03017168', 'n03018349', 'n03026506', 'n03028079', 'n03032252', 'n03041632', 'n03042490']\n"
     ]
    }
   ],
   "source": [
    "# === Load Dataset using ImageFolder ===\n",
    "print(f\"[INFO] Loading dataset from: {DATASET_DIR}\")\n",
    "if not os.path.isdir(DATASET_DIR):\n",
    "    raise FileNotFoundError(f\"[ERROR] Dataset directory not found at '{DATASET_DIR}'.\")\n",
    "\n",
    "imagefolder_dataset = torchvision.datasets.ImageFolder(\n",
    "    root=DATASET_DIR,\n",
    "    transform=eval_transforms\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    imagefolder_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "num_classes = len(imagefolder_dataset.classes)\n",
    "print(f\"[INFO] Dataset loaded: {len(imagefolder_dataset)} images across {num_classes} classes.\")\n",
    "print(f\"[INFO] Class index order (alphabetical): {imagefolder_dataset.classes}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loading dataset-specific labels from: ../TestDataSet/labels_list.json\n",
      "[INFO] Building mapping from ImageFolder index to ImageNet index...\n",
      "[INFO] Label mapping built successfully.\n"
     ]
    }
   ],
   "source": [
    "# === Load Dataset-Specific Label Mappings from JSON ===\n",
    "print(f\"[INFO] Loading dataset-specific labels from: {LABELS_JSON_PATH}\")\n",
    "imagefolder_to_imagenet_map = {}\n",
    "\n",
    "with open(LABELS_JSON_PATH, \"r\") as f:\n",
    "    json_labels = json.load(f)\n",
    "\n",
    "if not isinstance(json_labels, list):\n",
    "    raise ValueError(\"Expected a list of label strings in the JSON file.\")\n",
    "\n",
    "num_json_labels = len(json_labels)\n",
    "\n",
    "if num_json_labels != num_classes:\n",
    "    print(\"\\n[WARNING] Class count mismatch!\")\n",
    "    print(f\"- ImageFolder found {num_classes} classes in '{DATASET_DIR}'\")\n",
    "    print(f\"- JSON file contains {num_json_labels} entries\")\n",
    "    print(\"[WARNING] Proceeding, but label mapping may be incorrect.\")\n",
    "\n",
    "print(\"[INFO] Building mapping from ImageFolder index to ImageNet index...\")\n",
    "parse_errors = 0\n",
    "\n",
    "for idx in range(min(num_classes, num_json_labels)):\n",
    "    label_entry = json_labels[idx]\n",
    "    match = re.match(r\"\\s*(\\d+)\\s*:\", label_entry)\n",
    "\n",
    "    if match:\n",
    "        imagenet_idx = int(match.group(1))\n",
    "        imagefolder_to_imagenet_map[idx] = imagenet_idx\n",
    "    else:\n",
    "        print(f\"[ERROR] Could not parse index from: '{label_entry}'\")\n",
    "        parse_errors += 1\n",
    "\n",
    "if parse_errors > 0:\n",
    "    print(f\"[WARNING] {parse_errors} label parsing errors encountered. Mapping may be incomplete.\")\n",
    "elif not imagefolder_to_imagenet_map:\n",
    "    print(\"[ERROR] No valid label mappings were created.\")\n",
    "else:\n",
    "    print(\"[INFO] Label mapping built successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Starting evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Batches: 100%|██████████| 16/16 [00:16<00:00,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[RESULT] Top-1 Accuracy: 76.00%\n",
      "[RESULT] Top-5 Accuracy: 94.20%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# === Evaluation Loop ===\n",
    "top1_correct = 0\n",
    "top5_correct = 0\n",
    "total_samples = 0\n",
    "\n",
    "print(\"[INFO] Starting evaluation...\")\n",
    "with torch.no_grad():\n",
    "    for images, folder_labels in tqdm(test_loader, desc=\"Evaluating Batches\"):\n",
    "        images = images.to(DEVICE)\n",
    "\n",
    "        # Map ImageFolder indices to actual ImageNet indices\n",
    "        valid_indices = []\n",
    "        true_imagenet_labels = []\n",
    "\n",
    "        for i, folder_idx in enumerate(folder_labels.tolist()):\n",
    "            if folder_idx in imagefolder_to_imagenet_map:\n",
    "                valid_indices.append(i)\n",
    "                true_imagenet_labels.append(imagefolder_to_imagenet_map[folder_idx])\n",
    "\n",
    "        if not valid_indices:\n",
    "            continue\n",
    "\n",
    "        images_valid = images[valid_indices]\n",
    "        targets = torch.tensor(true_imagenet_labels, dtype=torch.long).to(DEVICE)\n",
    "\n",
    "        outputs = model(images_valid)\n",
    "        _, top5_preds = torch.topk(outputs, k=5, dim=1)\n",
    "\n",
    "        total_samples += targets.size(0)\n",
    "\n",
    "        # Top-1 Accuracy\n",
    "        top1_correct += (top5_preds[:, 0] == targets).sum().item()\n",
    "\n",
    "        # Top-5 Accuracy\n",
    "        matches_top5 = (top5_preds == targets.view(-1, 1)).sum(dim=1)\n",
    "        top5_correct += matches_top5.sum().item()\n",
    "\n",
    "# Final Accuracy Results\n",
    "top1_acc = top1_correct / total_samples if total_samples > 0 else 0.0\n",
    "top5_acc = top5_correct / total_samples if total_samples > 0 else 0.0\n",
    "\n",
    "print(f\"[RESULT] Top-1 Accuracy: {top1_acc * 100:.2f}%\")\n",
    "print(f\"[RESULT] Top-5 Accuracy: {top5_acc * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Evaluation Summary ===\n",
      "Total Images Evaluated: 500\n",
      "Top-1 Accuracy: 76.00% (380/500)\n",
      "Top-5 Accuracy: 94.20% (471/500)\n"
     ]
    }
   ],
   "source": [
    "# === Final Accuracy Report ===\n",
    "if total_samples == 0:\n",
    "    print(\"\\nNo samples were evaluated. Check JSON structure, parsing logic, or folder setup.\")\n",
    "    top1_acc = 0.0\n",
    "    top5_acc = 0.0\n",
    "else:\n",
    "    top1_acc = (top1_correct / total_samples) * 100\n",
    "    top5_acc = (top5_correct / total_samples) * 100\n",
    "\n",
    "print(\"\\n=== Evaluation Summary ===\")\n",
    "print(f\"Total Images Evaluated: {total_samples}\")\n",
    "print(f\"Top-1 Accuracy: {top1_acc:.2f}% ({top1_correct}/{total_samples})\")\n",
    "print(f\"Top-5 Accuracy: {top5_acc:.2f}% ({top5_correct}/{total_samples})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
