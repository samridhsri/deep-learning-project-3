{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "import numpy as np\n",
    "from tqdm import tqdm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_DIR = \"../TestDataSet\"\n",
    "LABELS_JSON_PATH = os.path.join(DATASET_DIR, \"labels_list.json\")\n",
    "PRETRAINED_WEIGHTS = torchvision.models.ResNet34_Weights.IMAGENET1K_V1\n",
    "BATCH_SIZE = 32\n",
    "NUM_WORKERS = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Loading and Preparation\n",
    "\n",
    "Here we load a pre-trained ResNet-34 model and prepares it for evaluation:\n",
    "\n",
    "- **`torchvision.models.resnet34(weights=PRETRAINED_WEIGHTS)`**:  \n",
    "  Instantiates the ResNet-34 model with the specified pre-trained weights.\n",
    "\n",
    "- **`model.eval()`**:  \n",
    "  Sets the model to evaluation mode.  \n",
    "  This is crucial for disabling layers like dropout and ensuring consistent behavior of batch normalization layers during inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ResNet-34 model with ResNet34_Weights.IMAGENET1K_V1 weights...\n",
      "Model loaded and set to evaluation mode.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Loading ResNet-34 model with {PRETRAINED_WEIGHTS} weights...\")\n",
    "model = torchvision.models.resnet34(weights=PRETRAINED_WEIGHTS)\n",
    "model = model.to(DEVICE)\n",
    "model.eval()\n",
    "print(\"Model loaded and set to evaluation mode.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Transformations\n",
    "\n",
    "Here we define the image transformations that will be applied to the images before feeding them to the model:\n",
    "\n",
    "- **`MEAN_NORMS` and `STD_NORMS`**:  \n",
    "  These are the mean and standard deviation values used for normalizing the image data.  \n",
    "  These specific values are commonly used when working with models pre-trained on ImageNet.\n",
    "\n",
    "- **`T.Compose([...])`**:  \n",
    "  Combines multiple transformations into a single sequence.\n",
    "\n",
    "    - **`T.ToTensor()`**:  \n",
    "      Converts the image from a PIL Image or NumPy array to a PyTorch tensor and scales the pixel values to the range `[0, 1]`.\n",
    "\n",
    "    - **`T.Normalize(mean=MEAN_NORMS, std=STD_NORMS)`**:  \n",
    "      Normalizes the tensor by subtracting the mean and dividing by the standard deviation for each color channel.  \n",
    "      This is a standard preprocessing step for neural networks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "MEAN_NORMS = np.array([0.485, 0.456, 0.406])\n",
    "STD_NORMS = np.array([0.229, 0.224, 0.225])\n",
    "\n",
    "eval_transforms = T.Compose([\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=MEAN_NORMS, std=STD_NORMS)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Loading and DataLoader Creation\n",
    "\n",
    "This cell loads the image dataset using `ImageFolder` and prepares it with a `DataLoader`.  \n",
    "Images are organized into subfolders, and the defined transformations are applied during loading.  \n",
    "The `DataLoader` is configured with the specified batch size, number of workers, and uses pinned memory for efficient GPU data transfer.  \n",
    "The dataset directory is also validated, and dataset information is printed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loading dataset from: ../TestDataSet\n",
      "[INFO] Dataset loaded: 500 images across 100 classes.\n",
      "[INFO] Class index order (alphabetical): ['n02672831', 'n02676566', 'n02687172', 'n02690373', 'n02692877', 'n02699494', 'n02701002', 'n02704792', 'n02708093', 'n02727426', 'n02730930', 'n02747177', 'n02749479', 'n02769748', 'n02776631', 'n02777292', 'n02782093', 'n02783161', 'n02786058', 'n02787622', 'n02788148', 'n02790996', 'n02791124', 'n02791270', 'n02793495', 'n02794156', 'n02795169', 'n02797295', 'n02799071', 'n02802426', 'n02804414', 'n02804610', 'n02807133', 'n02808304', 'n02808440', 'n02814533', 'n02814860', 'n02815834', 'n02817516', 'n02823428', 'n02823750', 'n02825657', 'n02834397', 'n02835271', 'n02837789', 'n02840245', 'n02841315', 'n02843684', 'n02859443', 'n02860847', 'n02865351', 'n02869837', 'n02870880', 'n02871525', 'n02877765', 'n02879718', 'n02883205', 'n02892201', 'n02892767', 'n02894605', 'n02895154', 'n02906734', 'n02909870', 'n02910353', 'n02916936', 'n02917067', 'n02927161', 'n02930766', 'n02939185', 'n02948072', 'n02950826', 'n02951358', 'n02951585', 'n02963159', 'n02965783', 'n02966193', 'n02966687', 'n02971356', 'n02974003', 'n02977058', 'n02978881', 'n02979186', 'n02980441', 'n02981792', 'n02988304', 'n02992211', 'n02992529', 'n02999410', 'n03000134', 'n03000247', 'n03000684', 'n03014705', 'n03016953', 'n03017168', 'n03018349', 'n03026506', 'n03028079', 'n03032252', 'n03041632', 'n03042490']\n"
     ]
    }
   ],
   "source": [
    "# === Load Dataset using ImageFolder ===\n",
    "print(f\"[INFO] Loading dataset from: {DATASET_DIR}\")\n",
    "if not os.path.isdir(DATASET_DIR):\n",
    "    raise FileNotFoundError(f\"[ERROR] Dataset directory not found at '{DATASET_DIR}'.\")\n",
    "\n",
    "imagefolder_dataset = torchvision.datasets.ImageFolder(\n",
    "    root=DATASET_DIR,\n",
    "    transform=eval_transforms\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    imagefolder_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "num_classes = len(imagefolder_dataset.classes)\n",
    "print(f\"[INFO] Dataset loaded: {len(imagefolder_dataset)} images across {num_classes} classes.\")\n",
    "print(f\"[INFO] Class index order (alphabetical): {imagefolder_dataset.classes}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label Mapping from JSON\n",
    "\n",
    "Now load a JSON file to map `ImageFolder` class indices to ImageNet class indices.  \n",
    "It validates the loaded data, checks for mismatches in class counts, extracts indices using regular expressions, and handles errors if label parsing fails.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loading dataset-specific labels from: ../TestDataSet/labels_list.json\n",
      "[INFO] Building mapping from ImageFolder index to ImageNet index...\n",
      "[INFO] Label mapping built successfully.\n"
     ]
    }
   ],
   "source": [
    "# === Load Dataset-Specific Label Mappings from JSON ===\n",
    "print(f\"[INFO] Loading dataset-specific labels from: {LABELS_JSON_PATH}\")\n",
    "imagefolder_to_imagenet_map = {}\n",
    "\n",
    "with open(LABELS_JSON_PATH, \"r\") as f:\n",
    "    json_labels = json.load(f)\n",
    "\n",
    "if not isinstance(json_labels, list):\n",
    "    raise ValueError(\"Expected a list of label strings in the JSON file.\")\n",
    "\n",
    "num_json_labels = len(json_labels)\n",
    "\n",
    "if num_json_labels != num_classes:\n",
    "    print(\"\\n[WARNING] Class count mismatch!\")\n",
    "    print(f\"- ImageFolder found {num_classes} classes in '{DATASET_DIR}'\")\n",
    "    print(f\"- JSON file contains {num_json_labels} entries\")\n",
    "    print(\"[WARNING] Proceeding, but label mapping may be incorrect.\")\n",
    "\n",
    "print(\"[INFO] Building mapping from ImageFolder index to ImageNet index...\")\n",
    "parse_errors = 0\n",
    "\n",
    "for idx in range(min(num_classes, num_json_labels)):\n",
    "    label_entry = json_labels[idx]\n",
    "    match = re.match(r\"\\s*(\\d+)\\s*:\", label_entry)\n",
    "\n",
    "    if match:\n",
    "        imagenet_idx = int(match.group(1))\n",
    "        imagefolder_to_imagenet_map[idx] = imagenet_idx\n",
    "    else:\n",
    "        print(f\"[ERROR] Could not parse index from: '{label_entry}'\")\n",
    "        parse_errors += 1\n",
    "\n",
    "if parse_errors > 0:\n",
    "    print(f\"[WARNING] {parse_errors} label parsing errors encountered. Mapping may be incomplete.\")\n",
    "elif not imagefolder_to_imagenet_map:\n",
    "    print(\"[ERROR] No valid label mappings were created.\")\n",
    "else:\n",
    "    print(\"[INFO] Label mapping built successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation Loop\n",
    "\n",
    "We perform the evaluation of the model:\n",
    "\n",
    "- Using `torch.no_grad()` to disable gradient calculation for efficient inference.\n",
    "- Iterate over batches from `test_loader` with a progress bar using `tqdm`.\n",
    "- Move each batch of images to the selected device (`cuda` or `cpu`).\n",
    "- Map `ImageFolder` labels to ImageNet indices, filtering out any samples without a valid mapping.\n",
    "- Feed valid images to the model to obtain output logits.\n",
    "- Extract Top-5 predictions for each image using `torch.topk`.\n",
    "- Calculate Top-1 accuracy by checking if the top prediction matches the target label.\n",
    "- Calculate Top-5 accuracy by checking if the target label is within the top 5 predictions.\n",
    "- Update counters for each batch and, after all batches, computes and prints the overall Top-1 and Top-5 accuracies.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Starting evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Batches: 100%|██████████| 16/16 [00:15<00:00,  1.02it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "top1_correct = 0\n",
    "top5_correct = 0\n",
    "total_samples = 0\n",
    "\n",
    "print(\"[INFO] Starting evaluation...\")\n",
    "with torch.no_grad():\n",
    "    for images, folder_labels in tqdm(test_loader, desc=\"Evaluating Batches\"):\n",
    "        images = images.to(DEVICE)\n",
    "\n",
    "        # Map ImageFolder indices to actual ImageNet indices\n",
    "        valid_indices = []\n",
    "        true_imagenet_labels = []\n",
    "\n",
    "        for i, folder_idx in enumerate(folder_labels.tolist()):\n",
    "            if folder_idx in imagefolder_to_imagenet_map:\n",
    "                valid_indices.append(i)\n",
    "                true_imagenet_labels.append(imagefolder_to_imagenet_map[folder_idx])\n",
    "\n",
    "        if not valid_indices:\n",
    "            continue\n",
    "\n",
    "        images_valid = images[valid_indices]\n",
    "        targets = torch.tensor(true_imagenet_labels, dtype=torch.long).to(DEVICE)\n",
    "\n",
    "        outputs = model(images_valid)\n",
    "        _, top5_preds = torch.topk(outputs, k=5, dim=1)\n",
    "\n",
    "        total_samples += targets.size(0)\n",
    "\n",
    "        # Top-1 Accuracy\n",
    "        top1_correct += (top5_preds[:, 0] == targets).sum().item()\n",
    "\n",
    "        # Top-5 Accuracy\n",
    "        matches_top5 = (top5_preds == targets.view(-1, 1)).sum(dim=1)\n",
    "        top5_correct += matches_top5.sum().item()\n",
    "\n",
    "# Final Accuracy Results\n",
    "top1_acc = top1_correct / total_samples if total_samples > 0 else 0.0\n",
    "top5_acc = top5_correct / total_samples if total_samples > 0 else 0.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Evaluation Summary ===\n",
      "Total Images Evaluated: 500\n",
      "Top-1 Accuracy: 76.00% (380/500)\n",
      "Top-5 Accuracy: 94.00% (470/500)\n"
     ]
    }
   ],
   "source": [
    "# === Final Accuracy Report ===\n",
    "if total_samples == 0:\n",
    "    print(\"\\nNo samples were evaluated. Check JSON structure, parsing logic, or folder setup.\")\n",
    "    top1_acc = 0.0\n",
    "    top5_acc = 0.0\n",
    "else:\n",
    "    top1_acc = (top1_correct / total_samples) * 100\n",
    "    top5_acc = (top5_correct / total_samples) * 100\n",
    "\n",
    "print(\"\\n=== Evaluation Summary ===\")\n",
    "print(f\"Total Images Evaluated: {total_samples}\")\n",
    "print(f\"Top-1 Accuracy: {top1_acc:.2f}% ({top1_correct}/{total_samples})\")\n",
    "print(f\"Top-5 Accuracy: {top5_acc:.2f}% ({top5_correct}/{total_samples})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation Results Calculation\n",
    "\n",
    "- **Top-1 Accuracy: 76.00% (380/500)**  \n",
    "  Here we measure the percentage of images where the model's top prediction matches the true class.  \n",
    "  - Correct predictions: 380  \n",
    "  - Calculation: `(380 / 500) * 100 = 76.00%`  \n",
    "  This means the model correctly identified the primary class for 76% of the images.\n",
    "\n",
    "- **Top-5 Accuracy: 94.20% (470/500)**  \n",
    "  Measure the percentage of images where the true class is among the model's top 5 predictions.  \n",
    "  - Correct predictions within top 5: 470  \n",
    "  - Calculation: `(470 / 500) * 100 = 94.00%`  \n",
    "  This shows the model included the true class in its top 5 guesses for 94.2% of the images.\n",
    "\n",
    "#### Summary\n",
    "The results indicate that the pre-trained ResNet-34 model performs well on the test dataset, achieving 76% Top-1 and over 94% Top-5 accuracy.  \n",
    "This suggests the dataset likely contains classes somewhat similar to those the model was trained on (ImageNet), indicating that the model performs well at classifying images from these 100 classes, successfully placing the correct label in its top 5 predictions for the vast majority of samples.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
